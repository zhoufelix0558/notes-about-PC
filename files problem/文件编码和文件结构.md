## 文件大小和占用空间的区别
**预备知识**：硬盘上资料的最小存储单位空间：`簇`（字节是计算单位，两者不一样）
- 一个文件如果小于一个簇，那它还是要占用这个簇的，并且是占够整个簇的空间。
- 如果大于一个簇，就会在硬盘上分散起来存放，这就是所谓的磁盘碎片了。

**例**：在现在硬盘常用的文件系统Fat32情况下，50G的分区，一个簇就有32KB。

**解决方案**：可以将分区划分得小一些，簇就会相应小一些。最好的办法是改用NTFS文件系统，可以自定义“簇”的大小。

**实例**：一个csv文件

| 大小       | 占用空间   |
| :--------: | :-----:  |
| 113,103 bytes|131,072 bytes |
| 110KB    |   128KB   |


## utf-8编码的文件显示不出中文，但是用notepad重新用utf-8保存后就能显示中文。
**生成环境**：python中pandas的to_CSV方法生成csv文件
**问题描述**：
- `test_org.csv`:直接生成的csv文件在excel打开的时候中文显示的是`??`,但是在notepad中打开能显示中文。
- `test_edit.csv`:间接生成的csv文件：notepad在保存的时候（编码原本是utf-8）还是保存成utf-8格式，替换原来的文件。

**分析**：
test_org.csv文件结构
```
EF BB BF 2C 74 69 6D 65 2C
         ,  t  i  m  e  , 
```
test_edit.csv文件结构
```
2C 74 69 6D 65 2C   //十六进制
,  t  i  m  e  ,    //ASCII码
```
**结论**：test_org.csv文件在notepad软件重新用utf-8保存之后文件头`EF BB BF`就去掉了。

|test_org.csv|test_edit.csv|
| :--------: | :-----:  |
| 113,103 bytes|131,072 bytes |
| 110KB    |   128KB   |

##csv文件编码比较
1. python pandas生成的`test.csv`
2. test.csv用notepad设置编码为ascii：`test_asc.csv`
3. test.csv用notepad设置编码为utf-8：`test_utf.csv`

|文件名|大小|excel显示|notepad显示|
| :----: | :---:  |:----: | :---:  |
|test.csv|113,103 bytes |??|正常|
|test_utf.csv|113,106 bytes|??|正常|
| test_asc.csv|107,549 bytes|正常|正常|

ASCII和UTF8在中文显示上的区别：（两个中文字符）
```
  F2 C5      CC 0D			//ascii 双字节
B9 B0 E7   9B 98 0D			//utf-8 三字节
```

## 文字编码的发展史
1. 美国人用一个字节的低7位编成`ascii`码，高位为0。后来欧洲人拓展成全字节编程（最多256个）。但是128-255在各种语言中显示不同的字符。
2. 中国人制定`GB2312`，双字节共65536种字符。
3. `unicode`统一全世界的字符（3-4字符）（100多万个符号），问题是x86和amd体系结构的电脑**小端序**和**大端序**都分不清。另外就是英语字母存储起来浪费空间。所以后来出现了Unicode的多种**存储方式**。
4. 随着互联网的兴起，`utf-8`成为unicode最重要的实现方式之一（还有utf-16，utf-32等）。
utf-8是变长的编码方式。它可以用1-4个字符表示一个符号。如果一个字符的第一位是0，那么这个字符就是单独一个字节。如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。
5. Unicode和utf-8的字符编码表示是不同的。例如"严"的Unicode码是`4E25`，UTF-8码是`E4B8A5`。utf-8编码不仅考虑了编码，还考虑了存储，`E4B8A5`狮子啊存储识别编码的基础上塞进了`4E25`
6. 在utf-8中，ascii字符（`U+0000`到`U+007F`）。中文字符在utf-8中一般占3个字节，最常见的是`1110xxxx 10xxxxxx 10xxxxxx`






